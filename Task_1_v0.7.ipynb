{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a5a40db-53fe-4953-bdb5-45dccfead9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "import nltk\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "# Pfad zur Wikipedia-Textdatei\n",
    "dateipfad = r'..\\task1\\Case Dataset\\Data files\\NER_text_Wikipedia_crawl.txt'\n",
    "\n",
    "# Datei einlesen\n",
    "with open(dateipfad, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Text in Sätze aufteilen\n",
    "sentences = nltk.tokenize.sent_tokenize(text)\n",
    "\n",
    "# Farbcodes für Entitätstypen\n",
    "entity_colors = {\n",
    "    \"PER\": (\"yellow\", \"black\"),       # Person\n",
    "    \"LOC\": (\"green\", \"white\"),        # Ort\n",
    "    \"ORG\": (\"blue\", \"white\"),         # Organisation\n",
    "    \"MISC\": (\"gray\", \"white\"),        # Miscellaneous (Nationalitäten, Religionen, Produkte oder Ereignisse)\n",
    "    \"DATE\": (\"orange\", \"black\"),      # Datum\n",
    "    \"TIME\": (\"purple\", \"white\"),      # Zeit\n",
    "    \"MONEY\": (\"red\", \"white\"),        # Geld\n",
    "    \"PERCENT\": (\"lightblue\", \"black\"),# Prozent\n",
    "    \"QUANTITY\": (\"pink\", \"black\"),    # Menge\n",
    "    \"LAW\": (\"lightgreen\", \"black\"),   # Rechtliche Hinweise\n",
    "    \"LANGUAGE\": (\"beige\", \"black\")    # Sprache\n",
    "}\n",
    "\n",
    "def get_entity_style(entity_type):\n",
    "    return entity_colors.get(entity_type, (\"white\", \"black\"))\n",
    "\n",
    "# NER-Modelle (https://huggingface.co/models?pipeline_tag=token-classification&language=en&sort=downloads&search=ner)\n",
    "models = {\n",
    "    \"BERT Large (CoNLL-03 English)\": \"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "    \"Wikineural Multilingual NER (Babelscape)\": \"Babelscape/wikineural-multilingual-ner\",\n",
    "    \"BERT Large NER (dslim)\": \"dslim/bert-large-NER\"\n",
    "}\n",
    "\n",
    "def load_model(model_name):\n",
    "    if model_name in [\"Babelscape/wikineural-multilingual-ner\", \"dslim/bert-large-NER\"]:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "        return pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "    else:\n",
    "        return pipeline(\"ner\", model=model_name)\n",
    "\n",
    "def ner_predict(sentence, model_name):\n",
    "    ner_model = load_model(models[model_name])\n",
    "    ner_results = ner_model(sentence)\n",
    "    highlighted_text = sentence\n",
    "    offset = 0\n",
    "\n",
    "    # Text markieren\n",
    "    for entity in ner_results:\n",
    "        entity_type = entity.get('entity_group', entity.get('entity'))\n",
    "        start = entity['start'] + offset\n",
    "        end = entity['end'] + offset\n",
    "        entity_text = highlighted_text[start:end]\n",
    "        bg_color, text_color = get_entity_style(entity_type)\n",
    "        highlighted_text = (highlighted_text[:start] +\n",
    "                            f\"<mark style='background-color: {bg_color}; color: {text_color}'>{entity_text}</mark>\" +\n",
    "                            highlighted_text[end:])\n",
    "        offset += len(f\"<mark style='background-color: {bg_color}; color: {text_color}'>{entity_text}</mark>\") - len(entity_text)\n",
    "\n",
    "    return highlighted_text + legend_html\n",
    "\n",
    "legend_html = \"\"\"\n",
    "<div style='margin-top: 20px;'>\n",
    "    <strong>Legende:</strong><br>\n",
    "    <mark style='background-color: yellow; color: black;'>Person</mark>\n",
    "    <mark style='background-color: green; color: white;'>Ort</mark>\n",
    "    <mark style='background-color: blue; color: white;'>Organisation</mark>\n",
    "    <mark style='background-color: gray; color: white;'>Miscellaneous</mark>\n",
    "    <mark style='background-color: orange; color: black;'>Datum</mark>\n",
    "    <mark style='background-color: purple; color: white;'>Zeit</mark>\n",
    "    <mark style='background-color: red; color: white;'>Geld</mark>\n",
    "    <mark style='background-color: lightblue; color: black;'>Prozent</mark>\n",
    "    <mark style='background-color: pink; color: black;'>Menge</mark>\n",
    "    <mark style='background-color: lightgreen; color: black;'>Rechtliche Hinweise</mark>\n",
    "    <mark style='background-color: beige; color: black;'>Sprache</mark>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=ner_predict,\n",
    "    inputs=[\n",
    "        gr.Dropdown(choices=sentences, label=\"Wähle einen Satz\"),\n",
    "        gr.Dropdown(choices=list(models.keys()), label=\"Wähle ein NER-Modell\")\n",
    "    ],\n",
    "    outputs=gr.HTML(label=\"NER-Ergebnisse\"),\n",
    "    title=\"Named Entity Recognition (NER)\",\n",
    "    description=\"Wähle einen Satz und ein Modell aus den Dropdown-Listen, um die benannten Entitäten hervorzuheben.\"\n",
    ")\n",
    "\n",
    "# Starte die Gradio-App\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8640e-94a7-48fa-a6da-7cc56528eead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f56c09b-fd05-4f80-b3ea-39e3c3ce3608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>split</th>\n",
       "      <th>en_US</th>\n",
       "      <th>de_DE</th>\n",
       "      <th>es_ES</th>\n",
       "      <th>fr_FR</th>\n",
       "      <th>it_IT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1847</td>\n",
       "      <td>train</td>\n",
       "      <td>order me a cheese burger from tommy's burgers</td>\n",
       "      <td>bestell mir einen cheeseburger von tommy's bur...</td>\n",
       "      <td>pídeme una hamburguesa de queso del mcdonalds</td>\n",
       "      <td>commande moi un burger au fromage chez tommy's...</td>\n",
       "      <td>ordinami un cheese burger da america graffiti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>876</td>\n",
       "      <td>train</td>\n",
       "      <td>play kari jobe for me</td>\n",
       "      <td>spiel kari jobe für mich</td>\n",
       "      <td>pon melendi para mi</td>\n",
       "      <td>mets jacques brel ne me quitte pas</td>\n",
       "      <td>metti laura pausini per me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14494</td>\n",
       "      <td>train</td>\n",
       "      <td>what is i. b. m.'s stock worth</td>\n",
       "      <td>was ist i. b. m.'s aktie wert</td>\n",
       "      <td>cuál es el valor de las acciones del ibm</td>\n",
       "      <td>quelle est la valeur des actions d'i. b. m.</td>\n",
       "      <td>qual è il valore delle azioni generali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14366</td>\n",
       "      <td>train</td>\n",
       "      <td>will it be good to buy nike stock today</td>\n",
       "      <td>wäre es gut heute volkswagen aktien zu kaufen</td>\n",
       "      <td>será bueno comprar acciones de nike hoy dia</td>\n",
       "      <td>sera-t-il bon d'acheter des actions nike aujou...</td>\n",
       "      <td>oggi è un buon giorno per comprare le azioni d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1977</td>\n",
       "      <td>train</td>\n",
       "      <td>please remove the alarm which i set for today ...</td>\n",
       "      <td>bitte lösche den wecker den ich für heute früh...</td>\n",
       "      <td>por favor borrar la alarma que tenía activada ...</td>\n",
       "      <td>veuillez retirer l'alarme que j'ai réglée pour...</td>\n",
       "      <td>rimuovi la sveglia impostata per questa mattina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  split                                              en_US  \\\n",
       "0   1847  train      order me a cheese burger from tommy's burgers   \n",
       "1    876  train                              play kari jobe for me   \n",
       "2  14494  train                     what is i. b. m.'s stock worth   \n",
       "3  14366  train            will it be good to buy nike stock today   \n",
       "4   1977  train  please remove the alarm which i set for today ...   \n",
       "\n",
       "                                               de_DE  \\\n",
       "0  bestell mir einen cheeseburger von tommy's bur...   \n",
       "1                           spiel kari jobe für mich   \n",
       "2                      was ist i. b. m.'s aktie wert   \n",
       "3      wäre es gut heute volkswagen aktien zu kaufen   \n",
       "4  bitte lösche den wecker den ich für heute früh...   \n",
       "\n",
       "                                               es_ES  \\\n",
       "0      pídeme una hamburguesa de queso del mcdonalds   \n",
       "1                                pon melendi para mi   \n",
       "2           cuál es el valor de las acciones del ibm   \n",
       "3        será bueno comprar acciones de nike hoy dia   \n",
       "4  por favor borrar la alarma que tenía activada ...   \n",
       "\n",
       "                                               fr_FR  \\\n",
       "0  commande moi un burger au fromage chez tommy's...   \n",
       "1                 mets jacques brel ne me quitte pas   \n",
       "2        quelle est la valeur des actions d'i. b. m.   \n",
       "3  sera-t-il bon d'acheter des actions nike aujou...   \n",
       "4  veuillez retirer l'alarme que j'ai réglée pour...   \n",
       "\n",
       "                                               it_IT  \n",
       "0      ordinami un cheese burger da america graffiti  \n",
       "1                         metti laura pausini per me  \n",
       "2             qual è il valore delle azioni generali  \n",
       "3  oggi è un buon giorno per comprare le azioni d...  \n",
       "4    rimuovi la sveglia impostata per questa mattina  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pfad zur CSV-Datei\n",
    "dateipfad = r'..\\task1\\Case Dataset\\Data files\\Translation_Training.csv'\n",
    "\n",
    "# CSV-Datei laden\n",
    "translation_data = pd.read_csv(dateipfad, delimiter=';')\n",
    "\n",
    "# Anzeigen der ersten Zeilen\n",
    "translation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119767d0-991c-446f-9cd9-8e0d486ba4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langdetect #https://www.edenai.co/post/top-free-language-detection-tools-apis-and-open-source-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba791923-d33b-4d3a-b022-f692f4051884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53021994-c4f9-4f01-8b30-8cb78bc3fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "from langdetect import detect\n",
    "import itertools\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207c341b-123d-4ccf-972d-83c70cd06710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modell geladen: Helsinki-NLP/opus-mt-en-de\n",
      "Modell geladen: facebook/m2m100_418M\n"
     ]
    }
   ],
   "source": [
    "# Liste der Sprachen gemäß .csv-Datei\n",
    "languages = ['en', 'de', 'es', 'fr', 'it']\n",
    "models = ['Helsinki', 'Facebook']\n",
    "language_pairs = list(itertools.permutations(languages, 2))\n",
    "\n",
    "translators = {}\n",
    "\n",
    "# Übersetzungsmodell laden, basierend auf Eingaben für Quellsprache (src), Zielsprache (dest) und Modell (model_choice).\n",
    "def load_model(src, dest, model_choice):\n",
    "    if model_choice == 'Helsinki':\n",
    "        model_name = f'Helsinki-NLP/opus-mt-{src}-{dest}'\n",
    "        translator = pipeline('translation', model=model_name)\n",
    "    elif model_choice == 'Facebook':\n",
    "        model_name = 'facebook/m2m100_418M'\n",
    "        translator = pipeline('translation', model=model_name, \n",
    "                              tokenizer=model_name, src_lang=src, tgt_lang=dest)\n",
    "    else:\n",
    "        return None, f\"Kein Modell verfügbar für die Kombination {src}-{dest} mit {model_choice}\"\n",
    "\n",
    "    print(f\"Modell geladen: {model_name}\")\n",
    "    return translator, None\n",
    "\n",
    "#Verwendung des ausgewählten Modells zu übersetzen\n",
    "def translate(text, src, dest, model_choice):\n",
    "    model_key = (src, dest, model_choice)\n",
    "    if model_key not in translators:\n",
    "        translator, error = load_model(src, dest, model_choice)\n",
    "        if error:\n",
    "            return error\n",
    "        translators[model_key] = translator\n",
    "\n",
    "    try:\n",
    "        translation = translators[model_key](text)[0]['translation_text']\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        return f\"Fehler bei der Übersetzung: {e}\"\n",
    "\n",
    "# Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=lambda text, dest, model_choice: translate(text, detect(text), dest, model_choice),\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, placeholder=\"Hier Text eingeben...\"), \n",
    "        gr.Dropdown(choices=languages, label=\"Zielsprache auswählen\"),\n",
    "        gr.Dropdown(choices=models, label=\"Modell auswählen\")\n",
    "    ],\n",
    "    outputs=\"text\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee315cc-e5ca-4a7b-900a-a6cce9ffac05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29b85ca-4b3c-4fa8-8c7f-7d34608cdc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By . Anthony Bond . PUBLISHED: . 07:03 EST, 2 ...</td>\n",
       "      <td>John and .\\nAudrey Cook were discovered alongs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNITED NATIONS (CNN) -- A rare meeting of U.N....</td>\n",
       "      <td>NEW: Libya can serve as example of cooperation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cover-up: Former Archbishop Lord Hope allowed ...</td>\n",
       "      <td>Very Reverend Robert Waddington sexually abuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>By . Kristie Lau . PUBLISHED: . 10:48 EST, 14 ...</td>\n",
       "      <td>Monday night's episode showed Buddy Valastro t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'The lamps are going out all over Europe. We s...</td>\n",
       "      <td>People asked to turn out lights for hour betwe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  By . Anthony Bond . PUBLISHED: . 07:03 EST, 2 ...   \n",
       "1  UNITED NATIONS (CNN) -- A rare meeting of U.N....   \n",
       "2  Cover-up: Former Archbishop Lord Hope allowed ...   \n",
       "3  By . Kristie Lau . PUBLISHED: . 10:48 EST, 14 ...   \n",
       "4  'The lamps are going out all over Europe. We s...   \n",
       "\n",
       "                                          highlights  \n",
       "0  John and .\\nAudrey Cook were discovered alongs...  \n",
       "1  NEW: Libya can serve as example of cooperation...  \n",
       "2  Very Reverend Robert Waddington sexually abuse...  \n",
       "3  Monday night's episode showed Buddy Valastro t...  \n",
       "4  People asked to turn out lights for hour betwe...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pfad zur CSV-Datei\n",
    "dateipfad = r'..\\task1\\Case Dataset\\Data files\\Summarization_Training.csv'\n",
    "\n",
    "# CSV-Datei laden\n",
    "summarization_data = pd.read_csv(dateipfad, delimiter=';')\n",
    "\n",
    "# Anzeigen der ersten Zeilen\n",
    "summarization_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2832ffac-d0a7-41e7-b22c-59d4d0a3d369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-newsroom and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modell geladen: google/pegasus-newsroom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\gradio\\queueing.py\", line 527, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\gradio\\route_utils.py\", line 270, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\gradio\\blocks.py\", line 1887, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\gradio\\blocks.py\", line 1472, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\gradio\\utils.py\", line 808, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\papad\\AppData\\Local\\Temp\\ipykernel_11296\\780710877.py\", line 42, in summarize_article\n",
      "    summary = summarizer(article_text, max_length=130, min_length=30, do_sample=False)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 265, in __call__\n",
      "    return super().__call__(*args, **kwargs)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 165, in __call__\n",
      "    result = super().__call__(*args, **kwargs)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 1129, in __call__\n",
      "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 1136, in run_single\n",
      "    model_outputs = self.forward(model_inputs, **forward_params)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 1035, in forward\n",
      "    model_outputs = self._forward(model_inputs, **forward_params)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 187, in _forward\n",
      "    output_ids = self.model.generate(**model_inputs, **generate_kwargs)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\generation\\utils.py\", line 1486, in generate\n",
      "    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\generation\\utils.py\", line 655, in _prepare_encoder_decoder_kwargs_for_generation\n",
      "    model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder(**encoder_kwargs)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\", line 771, in forward\n",
      "    embed_pos = self.embed_positions(input_shape)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py\", line 140, in forward\n",
      "    return super().forward(positions)\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\", line 162, in forward\n",
      "    return F.embedding(\n",
      "  File \"C:\\Users\\papad\\anaconda3\\envs\\datascience\\lib\\site-packages\\torch\\nn\\functional.py\", line 2210, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "IndexError: index out of range in self\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modell geladen: philschmid/bart-large-cnn-samsum\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "# Datei laden\n",
    "file_path = r'..\\task1\\Case Dataset\\Data files\\Summarization_Training.csv'\n",
    "data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Artikeltexte extrahieren\n",
    "articles = data['article'].tolist()\n",
    "\n",
    "# Modelle\n",
    "model_options = {\n",
    "    \"BART Large CNN\": \"facebook/bart-large-cnn\",\n",
    "    \"PEGASUS Newsroom\": \"google/pegasus-newsroom\",\n",
    "    \"BART Large CNN SAMSum\": \"philschmid/bart-large-cnn-samsum\"\n",
    "}\n",
    "\n",
    "# Initialisierung des Modells\n",
    "def load_model(model_choice):\n",
    "    try:\n",
    "        model_name = model_options[model_choice]\n",
    "        summarizer = pipeline(\"summarization\", model=model_name)\n",
    "        print(f\"Modell geladen: {model_name}\")\n",
    "        return summarizer\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "\n",
    "# Zusammenfassung ausführen\n",
    "def summarize_article(article_index, model_choice):\n",
    "    result = load_model(model_choice)\n",
    "    if isinstance(result, tuple): \n",
    "        summarizer, error = result\n",
    "        return error\n",
    "\n",
    "    summarizer = result\n",
    "\n",
    "    # Artikeltext holen\n",
    "    article_text = articles[int(article_index)]\n",
    "    \n",
    "    # Zusammenfassung erstellen\n",
    "    summary = summarizer(article_text, max_length=130, min_length=30, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "    \n",
    "# Dropdown zur Auswahl eines Artikels\n",
    "indices = [str(i) for i in range(len(articles))]\n",
    "\n",
    "# Gradio-Benutzeroberfläche einrichten\n",
    "demo = gr.Interface(\n",
    "    fn=summarize_article,\n",
    "    inputs=[\n",
    "        gr.Dropdown(choices=indices, label=\"Wähle einen Artikel anhand des Indexes\"),\n",
    "        gr.Dropdown(choices=list(model_options.keys()), label=\"Wähle ein Modell\")\n",
    "    ],\n",
    "    outputs=[gr.Textbox(label=\"Zusammengefasster Artikel\")]\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda652e-3c65-425e-9e08-d9a2fbd04384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
